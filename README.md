# Aplicaci칩n de un sistema de procesamiento del lenguaje natural (o "c칩mo haremos un clasificador autom치tico" 游눩)

Nuestra misi칩n durante las pr칩ximas semanas es aprender la implementaci칩n un clasificador autom치tico aplicando t칠cnicas de PLN. Lo haremos sin requerir de un lenguaje de programaci칩n, pues el foco del aprendizaje estar치 en los pasos que debemos realizar para pre-procesar, procesar, aplicar miner칤a textual y evaluar nuestro sistema. Llevaremos a cabo todas estas tareas de procesamiento utilizando el entorno inform치tico [DAMIEN (Data Mining Encountered)](http://www.fungramkb.com/nlp.aspx). 


# Mi칠rcoles 29 de septiembre
## Preliminares: 쯈u칠 es un clasificador?

Es un modelo estad칤stico basado en un algoritmo que es capaz de extraer informaci칩n a partir de conjuntos de datos previamente etiquetados o entrenados, para que la m치quina pueda etiquetar autom치ticamente conjuntos de datos nuevos, o corpus de prueba. As칤, el corpus de entrenamiento representa las etiquetas esperadas, mientras que el corpus de prueba es desde el cual se establecen las etiquetas predichas. 

`#SpoilerAlert!` Nuestro clasificador estar치 basado en la implementaci칩n del [algoritmo bayesiano ingenuo](https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo).

Para este ejemplo, desarrollaremos e implementaremos un clasificador que etiquete autom치ticamente el sentido de unidades l칠xicas potencialmente ambiguas. Utilizaremos para ello la palabra 춺cara췉, y consideraremos dos sentidos disponibles: FACE y SIDE. Esta infromaci칩n y las definiciones para cada sentido se encuentran disponibles en este [mini-diccionario](cara-data/cara-minidir.csv). 

## Primer paso: tareas de pre-procesamiento (parte 1)

### 1. Extracci칩n del cotexto
Vamos a extraer los datos correspondientes al cotexto para cada una de las instancias seleccionadas en [el corpus de 춺cara췉](cara-data/cara-corpus.txt). Consideren que el cotexto incluye la palabra objetivo `target` y la ventana con textual `window`.
````
Corpus > Open 
````

### 2. Generaci칩n de una colecci칩n de documentos (sin anotar)
Vamos a ejecutar un cambio de tama침o (file resizing) de archivo, mediante la aplicaci칩n de una expresi칩n regular para separar el contenido de cada cotexto en un determinado n칰mero de docuemntos (equivalente al n칰mero de filas de un input en formato `csv`.
````
Corpus > Pre-process > File resizing > Split (regex, \n)
````

### 3. Extracci칩n de etiquetas senseID
Vamos a extraer desde [el corpus de 춺cara췉](cara-data/cara-corpus.txt) las etiquetas senseID, correspondientes a cada uno de los sentidos seleccionados para las palabras objetivo en la colecci칩n de documentos.

## Segundo paso: tareas de pre-procesamiento (parte 2)

#### 4. Generaci칩n de la primera versi칩n de una matriz N-grama/documento
Vamos a procesar la colecci칩n de documentos correspondiente a los cotextos que contienen cada palabra objetivo, para as칤 establecer un an치lisis de la frecuencia de  de las unidades l칠xicas presentes en cada una de las instancias en an치lisis (revisaremos distintos settings para generar matrices).
````
Corpus > Process > Task: raw processing
````
----
















